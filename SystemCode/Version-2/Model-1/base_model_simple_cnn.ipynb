{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/Users/priyankapalaniselvam/Downloads/classifier_one_data/full_df.csv\")\n",
    "if 'ID' in df.columns:\n",
    "    df = df.drop('ID', axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['labels'] = label_encoder.fit_transform(df['labels'])\n",
    "df['labels'] = df['labels'].astype(str)\n",
    "left_images = df[['Left-Fundus', 'labels']]\n",
    "right_images = df[['Right-Fundus', 'labels']]\n",
    "\n",
    "left_images.columns = ['image', 'target']\n",
    "right_images.columns = ['image', 'target']\n",
    "\n",
    "combined_df = pd.concat([left_images, right_images])\n",
    "combined_df = combined_df.dropna(subset=['image'])\n",
    "\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10227 validated image filenames belonging to 8 classes.\n",
      "Found 2557 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='/Users/priyankapalaniselvam/Downloads/classifier_one_data/ODIR-5K/ODIR-5K/Training Images',\n",
    "    x_col='image',\n",
    "    y_col='target',\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='/Users/priyankapalaniselvam/Downloads/classifier_one_data/ODIR-5K/ODIR-5K/Training Images',\n",
    "    x_col=\"image\",\n",
    "    y_col=\"target\",\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test310/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test310/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 1s/step - accuracy: 0.4193 - loss: 1.7211 - val_accuracy: 0.4509 - val_loss: 1.5731\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 1s/step - accuracy: 0.4444 - loss: 1.5922 - val_accuracy: 0.4462 - val_loss: 1.5746\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 1s/step - accuracy: 0.4469 - loss: 1.5606 - val_accuracy: 0.4478 - val_loss: 1.5430\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 1s/step - accuracy: 0.4474 - loss: 1.5638 - val_accuracy: 0.4501 - val_loss: 1.5309\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m842s\u001b[0m 1s/step - accuracy: 0.4459 - loss: 1.5413 - val_accuracy: 0.4533 - val_loss: 1.4928\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1018s\u001b[0m 2s/step - accuracy: 0.4477 - loss: 1.5115 - val_accuracy: 0.4564 - val_loss: 1.4755\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 4s/step - accuracy: 0.4604 - loss: 1.4696 - val_accuracy: 0.4447 - val_loss: 1.4422\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10348s\u001b[0m 16s/step - accuracy: 0.4594 - loss: 1.4573 - val_accuracy: 0.4607 - val_loss: 1.4080\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 1s/step - accuracy: 0.4625 - loss: 1.4160 - val_accuracy: 0.4548 - val_loss: 1.4160\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 01:17:17.457921: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 4 of 8\n",
      "2024-10-29 01:17:19.819674: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1245s\u001b[0m 1s/step - accuracy: 0.4611 - loss: 1.4117 - val_accuracy: 0.4638 - val_loss: 1.3756\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 2s/step - accuracy: 0.4764 - loss: 1.3747 - val_accuracy: 0.4650 - val_loss: 1.3590\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1280s\u001b[0m 2s/step - accuracy: 0.4675 - loss: 1.3749 - val_accuracy: 0.4642 - val_loss: 1.3360\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1169s\u001b[0m 2s/step - accuracy: 0.4755 - loss: 1.3438 - val_accuracy: 0.4806 - val_loss: 1.3210\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1154s\u001b[0m 2s/step - accuracy: 0.4800 - loss: 1.3341 - val_accuracy: 0.4955 - val_loss: 1.3145\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1134s\u001b[0m 2s/step - accuracy: 0.4815 - loss: 1.3281 - val_accuracy: 0.4885 - val_loss: 1.3039\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 2s/step - accuracy: 0.4926 - loss: 1.2971 - val_accuracy: 0.5025 - val_loss: 1.2976\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1109s\u001b[0m 2s/step - accuracy: 0.4924 - loss: 1.2614 - val_accuracy: 0.5088 - val_loss: 1.2867\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1084s\u001b[0m 2s/step - accuracy: 0.4966 - loss: 1.2661 - val_accuracy: 0.4892 - val_loss: 1.2808\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1071s\u001b[0m 2s/step - accuracy: 0.5151 - loss: 1.2293 - val_accuracy: 0.4990 - val_loss: 1.2685\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1076s\u001b[0m 2s/step - accuracy: 0.5135 - loss: 1.2199 - val_accuracy: 0.5049 - val_loss: 1.2697\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('base_model_cn.weights.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
