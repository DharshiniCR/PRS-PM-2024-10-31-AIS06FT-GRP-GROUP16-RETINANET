{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"/Users/priyankapalaniselvam/Downloads/classifier_one_data/full_df.csv\")\n",
    "if 'ID' in df.columns:\n",
    "    df = df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['labels'] = label_encoder.fit_transform(df['labels'])\n",
    "df['labels'] = df['labels'].astype(str)\n",
    "left_images = df[['Left-Fundus', 'labels']]\n",
    "right_images = df[['Right-Fundus', 'labels']]\n",
    "\n",
    "left_images.columns = ['image', 'target']\n",
    "right_images.columns = ['image', 'target']\n",
    "\n",
    "combined_df = pd.concat([left_images, right_images])\n",
    "combined_df = combined_df.dropna(subset=['image'])\n",
    "\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10227 validated image filenames belonging to 8 classes.\n",
      "Found 2557 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='/Users/priyankapalaniselvam/Downloads/classifier_one_data/ODIR-5K/ODIR-5K/Training Images',\n",
    "    x_col='image',\n",
    "    y_col='target',\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='/Users/priyankapalaniselvam/Downloads/classifier_one_data/ODIR-5K/ODIR-5K/Training Images',\n",
    "    x_col=\"image\",\n",
    "    y_col=\"target\",\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "input_layer = Input(shape=input_shape)\n",
    "num_classes = 8\n",
    "base_model = Xception(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test310/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9609s\u001b[0m 15s/step - accuracy: 0.4714 - loss: 1.4946 - val_accuracy: 0.5823 - val_loss: 1.1486\n",
      "Epoch 2/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17163s\u001b[0m 27s/step - accuracy: 0.6266 - loss: 1.0264 - val_accuracy: 0.6019 - val_loss: 1.0887\n",
      "Epoch 3/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7799s\u001b[0m 12s/step - accuracy: 0.7254 - loss: 0.7552 - val_accuracy: 0.6672 - val_loss: 1.0064\n",
      "Epoch 4/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7287s\u001b[0m 11s/step - accuracy: 0.7890 - loss: 0.5821 - val_accuracy: 0.6750 - val_loss: 1.0438\n",
      "Epoch 5/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6198s\u001b[0m 10s/step - accuracy: 0.8248 - loss: 0.4666 - val_accuracy: 0.6883 - val_loss: 1.0926\n",
      "Epoch 6/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10042s\u001b[0m 16s/step - accuracy: 0.8458 - loss: 0.3903 - val_accuracy: 0.6711 - val_loss: 1.0880\n",
      "Epoch 7/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5296s\u001b[0m 8s/step - accuracy: 0.8500 - loss: 0.3415 - val_accuracy: 0.6723 - val_loss: 1.2231\n",
      "Epoch 8/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5831s\u001b[0m 9s/step - accuracy: 0.8487 - loss: 0.3181 - val_accuracy: 0.6824 - val_loss: 1.3498\n",
      "Epoch 9/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15563s\u001b[0m 24s/step - accuracy: 0.8627 - loss: 0.2983 - val_accuracy: 0.6762 - val_loss: 1.5721\n",
      "Epoch 10/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5011s\u001b[0m 8s/step - accuracy: 0.8535 - loss: 0.2793 - val_accuracy: 0.6680 - val_loss: 1.6640\n",
      "Epoch 11/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4708s\u001b[0m 7s/step - accuracy: 0.8606 - loss: 0.2644 - val_accuracy: 0.6836 - val_loss: 1.4480\n",
      "Epoch 12/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5329s\u001b[0m 8s/step - accuracy: 0.8572 - loss: 0.2538 - val_accuracy: 0.6672 - val_loss: 1.8256\n",
      "Epoch 13/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4785s\u001b[0m 7s/step - accuracy: 0.8542 - loss: 0.2543 - val_accuracy: 0.6820 - val_loss: 2.0663\n",
      "Epoch 14/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3906s\u001b[0m 6s/step - accuracy: 0.8632 - loss: 0.2458 - val_accuracy: 0.6871 - val_loss: 1.6934\n",
      "Epoch 15/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3953s\u001b[0m 6s/step - accuracy: 0.8660 - loss: 0.2348 - val_accuracy: 0.6836 - val_loss: 2.0376\n",
      "Epoch 16/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3938s\u001b[0m 6s/step - accuracy: 0.8625 - loss: 0.2424 - val_accuracy: 0.6879 - val_loss: 1.9847\n",
      "Epoch 17/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3831s\u001b[0m 6s/step - accuracy: 0.8718 - loss: 0.2192 - val_accuracy: 0.6844 - val_loss: 1.8186\n",
      "Epoch 18/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3878s\u001b[0m 6s/step - accuracy: 0.8727 - loss: 0.2200 - val_accuracy: 0.6848 - val_loss: 1.8703\n",
      "Epoch 19/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3940s\u001b[0m 6s/step - accuracy: 0.8682 - loss: 0.2355 - val_accuracy: 0.6785 - val_loss: 2.1549\n",
      "Epoch 20/20\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2639s\u001b[0m 4s/step - accuracy: 0.8676 - loss: 0.2170 - val_accuracy: 0.6867 - val_loss: 1.9838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    # callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('base_model_exc.weights.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
